{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAQ PM2.5 Data Analysis - 2023 Dataset\n",
    "\n",
    "Analysis of PM2.5 air quality data from OpenAQ for 2023.\n",
    "\n",
    "**Version**: V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "plt.rcParams['font.size'] = 10\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/vojtech/Code/Bard89/Project-Data/data/processed/jp_openaq_processed_20230101_to_20231231.csv'\n",
    "print(f\"Loading OpenAQ data from: {data_path}\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "print(f\"Dataset shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023 = df[(df['timestamp'] >= '2023-01-01') & (df['timestamp'] < '2024-01-01')]\n",
    "print(f\"2023 data: {len(df_2023):,} records\")\n",
    "print(f\"2023 date range: {df_2023['timestamp'].min()} to {df_2023['timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Info:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total records: {len(df_2023):,}\")\n",
    "print(f\"Unique hexagons (res8): {df_2023['h3_index_res8'].nunique():,}\")\n",
    "print(f\"Date range: {df_2023['timestamp'].min()} to {df_2023['timestamp'].max()}\")\n",
    "print(f\"\\nColumns ({len(df_2023.columns)}):\")\n",
    "for col in df_2023.columns:\n",
    "    print(f\"  - {col}: {df_2023[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 10 rows:\")\n",
    "display(df_2023.head(10))\n",
    "\n",
    "print(\"\\nLast 10 rows:\")\n",
    "display(df_2023.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Temporal Coverage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023['date'] = df_2023['timestamp'].dt.date\n",
    "all_dates_2023 = pd.date_range('2023-01-01', '2023-12-31', freq='D').date\n",
    "existing_dates = set(df_2023['date'].unique())\n",
    "missing_dates = sorted(set(all_dates_2023) - existing_dates)\n",
    "\n",
    "print(f\"Temporal Coverage Analysis for 2023:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Expected days in 2023: 365\")\n",
    "print(f\"Days with data: {len(existing_dates)}\")\n",
    "print(f\"Missing days: {len(missing_dates)}\")\n",
    "print(f\"Coverage: {len(existing_dates)/365*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n⚠️ DATA STARTS FROM: {df_2023['timestamp'].min().date()}\")\n",
    "print(f\"Missing period: 2023-01-01 to 2023-07-13 ({len(missing_dates)} days)\")\n",
    "\n",
    "print(\"\\nMonthly coverage:\")\n",
    "monthly_counts = df_2023.groupby(df_2023['timestamp'].dt.to_period('M')).size()\n",
    "all_months = pd.period_range('2023-01', '2023-12', freq='M')\n",
    "for month in all_months:\n",
    "    actual_records = monthly_counts.get(month, 0)\n",
    "    print(f\"  {month}: {actual_records:,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "calendar_data = np.zeros((12, 31))\n",
    "for date in all_dates_2023:\n",
    "    month = date.month - 1\n",
    "    day = date.day - 1\n",
    "    if day < 31:\n",
    "        calendar_data[month, day] = 1 if date in existing_dates else -1\n",
    "\n",
    "calendar_data[calendar_data == 0] = np.nan\n",
    "\n",
    "im = axes[0, 0].imshow(calendar_data, cmap='RdYlGn', aspect='auto', vmin=-1, vmax=1)\n",
    "axes[0, 0].set_title('2023 OpenAQ Data Availability Calendar', fontsize=12)\n",
    "axes[0, 0].set_xlabel('Day of Month')\n",
    "axes[0, 0].set_ylabel('Month')\n",
    "axes[0, 0].set_yticks(range(12))\n",
    "axes[0, 0].set_yticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                            'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "axes[0, 0].set_xticks(range(0, 31, 5))\n",
    "axes[0, 0].set_xticklabels(range(1, 32, 5))\n",
    "axes[0, 0].axhline(y=6.5, color='red', linewidth=2, linestyle='--', label='Data starts')\n",
    "plt.colorbar(im, ax=axes[0, 0], label='Data Available')\n",
    "\n",
    "date_range = pd.date_range('2023-01-01', '2023-12-31', freq='D')\n",
    "daily_counts = df_2023.groupby('date').size().reindex(date_range.date, fill_value=0)\n",
    "axes[0, 1].plot(daily_counts.index, daily_counts.values, linewidth=1)\n",
    "axes[0, 1].set_title('Daily Record Count Throughout 2023', fontsize=12)\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('Number of Records')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].set_xlim(date_range[0], date_range[-1])\n",
    "axes[0, 1].axvspan(pd.Timestamp('2023-01-01'), pd.Timestamp('2023-07-13'),\n",
    "                   color='red', alpha=0.2, label='Missing period')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "monthly_coverage = df_2023.groupby(df_2023['timestamp'].dt.to_period('M')).size().reindex(all_months, fill_value=0)\n",
    "colors = ['red' if i < 6 else 'orange' if i == 6 else 'green' for i in range(12)]\n",
    "bars = axes[1, 0].bar(range(12), monthly_coverage.values, color=colors, edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].set_title('Monthly Record Count for 2023', fontsize=12)\n",
    "axes[1, 0].set_xlabel('Month')\n",
    "axes[1, 0].set_ylabel('Number of Records')\n",
    "axes[1, 0].set_xticks(range(12))\n",
    "axes[1, 0].set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                             'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], rotation=45)\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, val in zip(bars, monthly_coverage.values):\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5000,\n",
    "                    f'{val:,}' if val > 0 else 'NO DATA', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "hourly_counts = df_2023.groupby(df_2023['timestamp'].dt.hour).size()\n",
    "axes[1, 1].bar(hourly_counts.index, hourly_counts.values, color='steelblue', edgecolor='black')\n",
    "axes[1, 1].set_title('Hourly Distribution of Records', fontsize=12)\n",
    "axes[1, 1].set_xlabel('Hour of Day')\n",
    "axes[1, 1].set_ylabel('Number of Records')\n",
    "axes[1, 1].set_xticks(range(0, 24, 2))\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Temporal Coverage Analysis - OpenAQ 2023', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PM2.5 Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_columns = [col for col in df_2023.columns if 'pm25' in col.lower()]\n",
    "print(f\"PM2.5 columns found: {pm25_columns}\")\n",
    "\n",
    "missing_stats = pd.DataFrame({\n",
    "    'Missing Count': df_2023[pm25_columns].isnull().sum(),\n",
    "    'Missing %': (df_2023[pm25_columns].isnull().sum() / len(df_2023) * 100).round(2),\n",
    "    'Available Count': df_2023[pm25_columns].notnull().sum(),\n",
    "    'Available %': (df_2023[pm25_columns].notnull().sum() / len(df_2023) * 100).round(2)\n",
    "})\n",
    "\n",
    "print(\"\\nPM2.5 Data Completeness:\")\n",
    "print(\"=\"*60)\n",
    "display(missing_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "pm25_mean = df_2023['pm25_ugm3_mean'].dropna()\n",
    "axes[0, 0].hist(pm25_mean[pm25_mean <= 100], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0, 0].set_xlabel('PM2.5 (μg/m³)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('PM2.5 Distribution (≤100 μg/m³)')\n",
    "axes[0, 0].axvline(pm25_mean.mean(), color='red', linestyle='--', label=f'Mean: {pm25_mean.mean():.1f}')\n",
    "axes[0, 0].axvline(pm25_mean.median(), color='green', linestyle='--', label=f'Median: {pm25_mean.median():.1f}')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "daily_pm25_missing = df_2023.groupby('date')['pm25_ugm3_mean'].apply(lambda x: x.isnull().mean() * 100)\n",
    "axes[0, 1].plot(daily_pm25_missing.index, daily_pm25_missing.values, linewidth=1)\n",
    "axes[0, 1].set_title('PM2.5 Missing Data Over Time', fontsize=12)\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('Missing %')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "monthly_pm25 = df_2023.groupby(df_2023['timestamp'].dt.month)['pm25_ugm3_mean'].mean()\n",
    "available_months = monthly_pm25.index\n",
    "axes[1, 0].bar(available_months, monthly_pm25.values, color='steelblue', edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Month')\n",
    "axes[1, 0].set_ylabel('Average PM2.5 (μg/m³)')\n",
    "axes[1, 0].set_title('Average PM2.5 by Month (Available Months Only)')\n",
    "axes[1, 0].set_xticks(available_months)\n",
    "axes[1, 0].set_xticklabels([['', '', '', '', '', '', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'][m-1] for m in available_months])\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "hourly_pm25 = df_2023.groupby(df_2023['timestamp'].dt.hour)['pm25_ugm3_mean'].mean()\n",
    "axes[1, 1].plot(hourly_pm25.index, hourly_pm25.values, marker='o', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Hour of Day')\n",
    "axes[1, 1].set_ylabel('Average PM2.5 (μg/m³)')\n",
    "axes[1, 1].set_title('Average PM2.5 by Hour of Day')\n",
    "axes[1, 1].set_xticks(range(0, 24, 2))\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('PM2.5 Data Analysis - OpenAQ 2023', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Geographic Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_locations = df_2023[['h3_index_res8', 'h3_lat_res8', 'h3_lon_res8']].drop_duplicates()\n",
    "print(f\"Geographic Coverage:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Unique hexagons: {len(hex_locations):,}\")\n",
    "print(f\"Latitude range: {hex_locations['h3_lat_res8'].min():.2f} to {hex_locations['h3_lat_res8'].max():.2f}\")\n",
    "print(f\"Longitude range: {hex_locations['h3_lon_res8'].min():.2f} to {hex_locations['h3_lon_res8'].max():.2f}\")\n",
    "\n",
    "hex_data_counts = df_2023.groupby('h3_index_res8').agg({\n",
    "    'pm25_ugm3_mean': ['count', 'mean', lambda x: x.notna().mean()]\n",
    "}).reset_index()\n",
    "hex_data_counts.columns = ['h3_index_res8', 'record_count', 'pm25_mean', 'pm25_coverage']\n",
    "hex_with_counts = hex_locations.merge(hex_data_counts, on='h3_index_res8')\n",
    "\n",
    "print(f\"\\nRecords per hexagon:\")\n",
    "print(f\"  Mean: {hex_with_counts['record_count'].mean():.0f}\")\n",
    "print(f\"  Median: {hex_with_counts['record_count'].median():.0f}\")\n",
    "print(f\"  Min: {hex_with_counts['record_count'].min()}\")\n",
    "print(f\"  Max: {hex_with_counts['record_count'].max()}\")\n",
    "\n",
    "print(f\"\\nPM2.5 data completeness per hexagon:\")\n",
    "print(f\"  Mean: {hex_with_counts['pm25_coverage'].mean():.1%}\")\n",
    "print(f\"  Median: {hex_with_counts['pm25_coverage'].median():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "scatter = axes[0].scatter(hex_with_counts['h3_lon_res8'],\n",
    "                         hex_with_counts['h3_lat_res8'],\n",
    "                         c=hex_with_counts['pm25_mean'],\n",
    "                         cmap='YlOrRd', s=20, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "axes[0].set_xlabel('Longitude')\n",
    "axes[0].set_ylabel('Latitude')\n",
    "axes[0].set_title('PM2.5 Monitoring Locations with Average PM2.5 Levels')\n",
    "plt.colorbar(scatter, ax=axes[0], label='Mean PM2.5 (μg/m³)')\n",
    "\n",
    "scatter2 = axes[1].scatter(hex_with_counts['h3_lon_res8'],\n",
    "                          hex_with_counts['h3_lat_res8'],\n",
    "                          c=hex_with_counts['pm25_coverage']*100,\n",
    "                          cmap='viridis', s=20, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "axes[1].set_xlabel('Longitude')\n",
    "axes[1].set_ylabel('Latitude')\n",
    "axes[1].set_title('PM2.5 Data Coverage by Location')\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Data Coverage (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PM2.5 Statistical Summary:\")\n",
    "print(\"=\"*60)\n",
    "display(df_2023[pm25_columns].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OPENAQ 2023 DATA QUALITY SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n📊 DATASET OVERVIEW:\")\n",
    "print(f\"   Total records: {len(df_2023):,}\")\n",
    "print(f\"   Time period: {df_2023['timestamp'].min().date()} to {df_2023['timestamp'].max().date()}\")\n",
    "print(f\"   Unique locations (hexagons): {df_2023['h3_index_res8'].nunique()}\")\n",
    "print(f\"   Temporal resolution: Hourly\")\n",
    "\n",
    "print(\"\\n⚠️ TEMPORAL COVERAGE:\")\n",
    "print(f\"   Days with data: {len(existing_dates)}/365 ({len(existing_dates)/365*100:.1f}%)\")\n",
    "print(f\"   ❌ MISSING: January 1 - July 13, 2023 (194 days)\")\n",
    "print(f\"   ✓ Available: July 14 - December 31, 2023 (171 days)\")\n",
    "\n",
    "print(\"\\n📈 PM2.5 STATISTICS (Available Period):\")\n",
    "print(f\"   Mean: {pm25_mean.mean():.2f} μg/m³\")\n",
    "print(f\"   Median: {pm25_mean.median():.2f} μg/m³\")\n",
    "print(f\"   Std Dev: {pm25_mean.std():.2f} μg/m³\")\n",
    "print(f\"   Min: {pm25_mean.min():.2f} μg/m³\")\n",
    "print(f\"   Max: {pm25_mean.max():.2f} μg/m³\")\n",
    "print(f\"   95th percentile: {pm25_mean.quantile(0.95):.2f} μg/m³\")\n",
    "\n",
    "print(\"\\n✅ DATA COMPLETENESS (Within Available Period):\")\n",
    "for col in pm25_columns:\n",
    "    completeness = df_2023[col].notna().mean() * 100\n",
    "    print(f\"   {col}: {completeness:.1f}%\")\n",
    "\n",
    "print(\"\\n🔴 CRITICAL FINDING:\")\n",
    "print(\"   The OpenAQ dataset is missing the first half of 2023 (Jan-Jul 13).\")\n",
    "print(\"   This explains why the enriched PM2.5 dataset only contains data\")\n",
    "print(\"   from July 14, 2023 onwards, despite having complete weather and\")\n",
    "print(\"   traffic data for the entire year.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}