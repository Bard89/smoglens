{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JARTIC Traffic Data Analysis - 2023 Dataset\n",
    "\n",
    "Analysis of traffic volume data from JARTIC for 2023.\n",
    "\n",
    "**Version**: V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "plt.rcParams['font.size'] = 10\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/vojtech/Code/Bard89/Project-Data/data/processed/jp_jartic_processed_20230101_to_20231231.csv'\n",
    "print(f\"Loading JARTIC data from: {data_path}\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "print(f\"Dataset shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023 = df[(df['timestamp'] >= '2023-01-01') & (df['timestamp'] < '2024-01-01')]\n",
    "print(f\"2023 data: {len(df_2023):,} records\")\n",
    "print(f\"2023 date range: {df_2023['timestamp'].min()} to {df_2023['timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Info:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total records: {len(df_2023):,}\")\n",
    "print(f\"Unique hexagons (res8): {df_2023['h3_index_res8'].nunique():,}\")\n",
    "print(f\"Date range: {df_2023['timestamp'].min()} to {df_2023['timestamp'].max()}\")\n",
    "print(f\"\\nColumns ({len(df_2023.columns)}):\")\n",
    "for col in df_2023.columns:\n",
    "    print(f\"  - {col}: {df_2023[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 10 rows:\")\n",
    "display(df_2023.head(10))\n",
    "\n",
    "print(\"\\nLast 10 rows:\")\n",
    "display(df_2023.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Temporal Coverage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023['date'] = df_2023['timestamp'].dt.date\n",
    "all_dates_2023 = pd.date_range('2023-01-01', '2023-12-31', freq='D').date\n",
    "existing_dates = set(df_2023['date'].unique())\n",
    "missing_dates = sorted(set(all_dates_2023) - existing_dates)\n",
    "\n",
    "print(f\"Temporal Coverage Analysis for 2023:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Expected days in 2023: 365\")\n",
    "print(f\"Days with data: {len(existing_dates)}\")\n",
    "print(f\"Missing days: {len(missing_dates)}\")\n",
    "print(f\"Coverage: {len(existing_dates)/365*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n✓ COMPLETE YEAR COVERAGE\" if len(existing_dates) >= 364 else f\"\\n⚠️ INCOMPLETE COVERAGE\")\n",
    "\n",
    "print(\"\\nMonthly coverage:\")\n",
    "monthly_counts = df_2023.groupby(df_2023['timestamp'].dt.to_period('M')).size()\n",
    "all_months = pd.period_range('2023-01', '2023-12', freq='M')\n",
    "for month in all_months:\n",
    "    actual_records = monthly_counts.get(month, 0)\n",
    "    print(f\"  {month}: {actual_records:,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "calendar_data = np.zeros((12, 31))\n",
    "for date in all_dates_2023:\n",
    "    month = date.month - 1\n",
    "    day = date.day - 1\n",
    "    if day < 31:\n",
    "        calendar_data[month, day] = 1 if date in existing_dates else -1\n",
    "\n",
    "calendar_data[calendar_data == 0] = np.nan\n",
    "\n",
    "im = axes[0, 0].imshow(calendar_data, cmap='RdYlGn', aspect='auto', vmin=-1, vmax=1)\n",
    "axes[0, 0].set_title('2023 JARTIC Data Availability Calendar', fontsize=12)\n",
    "axes[0, 0].set_xlabel('Day of Month')\n",
    "axes[0, 0].set_ylabel('Month')\n",
    "axes[0, 0].set_yticks(range(12))\n",
    "axes[0, 0].set_yticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                            'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "axes[0, 0].set_xticks(range(0, 31, 5))\n",
    "axes[0, 0].set_xticklabels(range(1, 32, 5))\n",
    "plt.colorbar(im, ax=axes[0, 0], label='Data Available')\n",
    "\n",
    "date_range = pd.date_range('2023-01-01', '2023-12-31', freq='D')\n",
    "daily_counts = df_2023.groupby('date').size().reindex(date_range.date, fill_value=0)\n",
    "axes[0, 1].plot(daily_counts.index, daily_counts.values, linewidth=1)\n",
    "axes[0, 1].set_title('Daily Record Count Throughout 2023', fontsize=12)\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('Number of Records')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].set_xlim(date_range[0], date_range[-1])\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "monthly_coverage = df_2023.groupby(df_2023['timestamp'].dt.to_period('M')).size().reindex(all_months, fill_value=0)\n",
    "colors = ['green' if val > 0 else 'red' for val in monthly_coverage.values]\n",
    "bars = axes[1, 0].bar(range(12), monthly_coverage.values, color=colors, edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].set_title('Monthly Record Count for 2023', fontsize=12)\n",
    "axes[1, 0].set_xlabel('Month')\n",
    "axes[1, 0].set_ylabel('Number of Records')\n",
    "axes[1, 0].set_xticks(range(12))\n",
    "axes[1, 0].set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                             'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], rotation=45)\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, val in zip(bars, monthly_coverage.values):\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5000,\n",
    "                    f'{val:,}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "hourly_counts = df_2023.groupby(df_2023['timestamp'].dt.hour).size()\n",
    "axes[1, 1].bar(hourly_counts.index, hourly_counts.values, color='steelblue', edgecolor='black')\n",
    "axes[1, 1].set_title('Hourly Distribution of Records', fontsize=12)\n",
    "axes[1, 1].set_xlabel('Hour of Day')\n",
    "axes[1, 1].set_ylabel('Number of Records')\n",
    "axes[1, 1].set_xticks(range(0, 24, 2))\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Temporal Coverage Analysis - JARTIC 2023', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Traffic Volume Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_columns = [col for col in df_2023.columns if 'traffic' in col.lower() and 'volume' in col.lower()]\n",
    "print(f\"Traffic volume columns found: {traffic_columns}\")\n",
    "\n",
    "missing_stats = pd.DataFrame({\n",
    "    'Missing Count': df_2023[traffic_columns].isnull().sum(),\n",
    "    'Missing %': (df_2023[traffic_columns].isnull().sum() / len(df_2023) * 100).round(2),\n",
    "    'Available Count': df_2023[traffic_columns].notnull().sum(),\n",
    "    'Available %': (df_2023[traffic_columns].notnull().sum() / len(df_2023) * 100).round(2)\n",
    "})\n",
    "\n",
    "print(\"\\nTraffic Data Completeness:\")\n",
    "print(\"=\"*60)\n",
    "display(missing_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "traffic_mean = df_2023['avg_traffic_volume'].dropna()\n",
    "axes[0, 0].hist(traffic_mean[traffic_mean <= 200], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0, 0].set_xlabel('Traffic Volume')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Traffic Volume Distribution (≤200)')\n",
    "axes[0, 0].axvline(traffic_mean.mean(), color='red', linestyle='--', label=f'Mean: {traffic_mean.mean():.1f}')\n",
    "axes[0, 0].axvline(traffic_mean.median(), color='green', linestyle='--', label=f'Median: {traffic_mean.median():.1f}')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "daily_traffic_missing = df_2023.groupby('date')['avg_traffic_volume'].apply(lambda x: x.isnull().mean() * 100)\n",
    "axes[0, 1].plot(daily_traffic_missing.index, daily_traffic_missing.values, linewidth=1)\n",
    "axes[0, 1].set_title('Traffic Data Missing Values Over Time', fontsize=12)\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('Missing %')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "monthly_traffic = df_2023.groupby(df_2023['timestamp'].dt.month)['avg_traffic_volume'].mean()\n",
    "axes[1, 0].bar(monthly_traffic.index, monthly_traffic.values, color='steelblue', edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Month')\n",
    "axes[1, 0].set_ylabel('Average Traffic Volume')\n",
    "axes[1, 0].set_title('Average Traffic Volume by Month')\n",
    "axes[1, 0].set_xticks(range(1, 13))\n",
    "axes[1, 0].set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                            'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "hourly_traffic = df_2023.groupby(df_2023['timestamp'].dt.hour)['avg_traffic_volume'].mean()\n",
    "axes[1, 1].plot(hourly_traffic.index, hourly_traffic.values, marker='o', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Hour of Day')\n",
    "axes[1, 1].set_ylabel('Average Traffic Volume')\n",
    "axes[1, 1].set_title('Average Traffic Volume by Hour of Day')\n",
    "axes[1, 1].set_xticks(range(0, 24, 2))\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Traffic Volume Analysis - JARTIC 2023', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Geographic Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_locations = df_2023[['h3_index_res8', 'h3_lat_res8', 'h3_lon_res8']].drop_duplicates()\n",
    "print(f\"Geographic Coverage:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Unique hexagons: {len(hex_locations):,}\")\n",
    "print(f\"Latitude range: {hex_locations['h3_lat_res8'].min():.2f} to {hex_locations['h3_lat_res8'].max():.2f}\")\n",
    "print(f\"Longitude range: {hex_locations['h3_lon_res8'].min():.2f} to {hex_locations['h3_lon_res8'].max():.2f}\")\n",
    "\n",
    "hex_data_counts = df_2023.groupby('h3_index_res8').agg({\n",
    "    'avg_traffic_volume': ['count', 'mean', lambda x: x.notna().mean()]\n",
    "}).reset_index()\n",
    "hex_data_counts.columns = ['h3_index_res8', 'record_count', 'traffic_mean', 'traffic_coverage']\n",
    "hex_with_counts = hex_locations.merge(hex_data_counts, on='h3_index_res8')\n",
    "\n",
    "print(f\"\\nRecords per hexagon:\")\n",
    "print(f\"  Mean: {hex_with_counts['record_count'].mean():.0f}\")\n",
    "print(f\"  Median: {hex_with_counts['record_count'].median():.0f}\")\n",
    "print(f\"  Min: {hex_with_counts['record_count'].min()}\")\n",
    "print(f\"  Max: {hex_with_counts['record_count'].max()}\")\n",
    "\n",
    "print(f\"\\nTraffic data completeness per hexagon:\")\n",
    "print(f\"  Mean: {hex_with_counts['traffic_coverage'].mean():.1%}\")\n",
    "print(f\"  Median: {hex_with_counts['traffic_coverage'].median():.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "scatter = axes[0].scatter(hex_with_counts['h3_lon_res8'],\n",
    "                         hex_with_counts['h3_lat_res8'],\n",
    "                         c=hex_with_counts['traffic_mean'],\n",
    "                         cmap='YlOrRd', s=20, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "axes[0].set_xlabel('Longitude')\n",
    "axes[0].set_ylabel('Latitude')\n",
    "axes[0].set_title('Traffic Monitoring Locations with Average Traffic Volume')\n",
    "plt.colorbar(scatter, ax=axes[0], label='Mean Traffic Volume')\n",
    "\n",
    "scatter2 = axes[1].scatter(hex_with_counts['h3_lon_res8'],\n",
    "                          hex_with_counts['h3_lat_res8'],\n",
    "                          c=hex_with_counts['traffic_coverage']*100,\n",
    "                          cmap='viridis', s=20, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "axes[1].set_xlabel('Longitude')\n",
    "axes[1].set_ylabel('Latitude')\n",
    "axes[1].set_title('Traffic Data Coverage by Location')\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Data Coverage (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Temporal Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2023['dayofweek'] = df_2023['timestamp'].dt.dayofweek\n",
    "df_2023['is_weekend'] = df_2023['dayofweek'].isin([5, 6])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "dow_traffic = df_2023.groupby('dayofweek')['avg_traffic_volume'].mean()\n",
    "axes[0].bar(dow_traffic.index, dow_traffic.values, color='steelblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Day of Week')\n",
    "axes[0].set_ylabel('Average Traffic Volume')\n",
    "axes[0].set_title('Average Traffic Volume by Day of Week')\n",
    "axes[0].set_xticks(range(7))\n",
    "axes[0].set_xticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "weekend_comparison = df_2023.groupby('is_weekend')['avg_traffic_volume'].mean()\n",
    "axes[1].bar(['Weekday', 'Weekend'], weekend_comparison.values, color=['blue', 'orange'], edgecolor='black')\n",
    "axes[1].set_ylabel('Average Traffic Volume')\n",
    "axes[1].set_title('Weekday vs Weekend Traffic Volume')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Temporal Traffic Patterns - JARTIC 2023', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Traffic Volume Statistical Summary:\")\n",
    "print(\"=\"*60)\n",
    "display(df_2023[traffic_columns].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"JARTIC 2023 DATA QUALITY SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n📊 DATASET OVERVIEW:\")\n",
    "print(f\"   Total records: {len(df_2023):,}\")\n",
    "print(f\"   Time period: {df_2023['timestamp'].min().date()} to {df_2023['timestamp'].max().date()}\")\n",
    "print(f\"   Unique locations (hexagons): {df_2023['h3_index_res8'].nunique()}\")\n",
    "print(f\"   Temporal resolution: Hourly\")\n",
    "\n",
    "print(\"\\n📅 TEMPORAL COVERAGE:\")\n",
    "print(f\"   Days with data: {len(existing_dates)}/365 ({len(existing_dates)/365*100:.1f}%)\")\n",
    "print(f\"   ✓ COMPLETE YEAR COVERAGE\" if len(existing_dates) >= 364 else f\"   ⚠️ Partial coverage\")\n",
    "print(f\"   ✓ January-June 2023: AVAILABLE\")\n",
    "print(f\"   ✓ July-December 2023: AVAILABLE\")\n",
    "\n",
    "print(\"\\n🚗 TRAFFIC STATISTICS:\")\n",
    "print(f\"   Mean: {traffic_mean.mean():.2f}\")\n",
    "print(f\"   Median: {traffic_mean.median():.2f}\")\n",
    "print(f\"   Std Dev: {traffic_mean.std():.2f}\")\n",
    "print(f\"   Min: {traffic_mean.min():.2f}\")\n",
    "print(f\"   Max: {traffic_mean.max():.2f}\")\n",
    "print(f\"   95th percentile: {traffic_mean.quantile(0.95):.2f}\")\n",
    "\n",
    "print(\"\\n✅ DATA COMPLETENESS:\")\n",
    "for col in traffic_columns:\n",
    "    completeness = df_2023[col].notna().mean() * 100\n",
    "    print(f\"   {col}: {completeness:.1f}%\")\n",
    "\n",
    "print(\"\\n🟢 KEY FINDING:\")\n",
    "print(\"   JARTIC traffic data has COMPLETE coverage for all of 2023.\")\n",
    "print(\"   This confirms that the missing Jan-Jul 13 period in the enriched\")\n",
    "print(\"   dataset is due to OpenAQ PM2.5 data availability, not traffic data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}